{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook:\n",
    "* The dataset and the original, pretained VGG16 is loaded\n",
    "* Drop the fully connected layers, and add three new fully connected layers. \n",
    "* Train this model for 30 epochs\n",
    "* Run for experiments, gradually increasing the number of filters pruned per iteration: 132, 264, 528, 1056\n",
    "* Track accuracy and running time for every experiment\n",
    "* Dump result to Pickle for analysis in another notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEchLkbtsI1h"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q58o6vLgsI1j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from operator import itemgetter\n",
    "from heapq import nsmallest\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a pruning target\n",
    "In this research, we will reduce the network size by 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLr_Vm9MovDu"
   },
   "outputs": [],
   "source": [
    "pruning_target = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cuJCiiNgx8k"
   },
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTnu3xlFsI1x"
   },
   "outputs": [],
   "source": [
    "def loader(path, batch_size=16, num_workers=4, pin_memory=True):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return data.DataLoader(\n",
    "        datasets.ImageFolder(path,\n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize,\n",
    "                             ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6I7Z__PsI13"
   },
   "outputs": [],
   "source": [
    "def test_loader(path, batch_size=32, num_workers=4, pin_memory=True):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return data.DataLoader(\n",
    "        datasets.ImageFolder(path,\n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize(256),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 normalize,\n",
    "                             ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sM5HBw2nsI1_"
   },
   "source": [
    "# Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PV1hCqw_-fVO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m9Rgm_MxsI2C",
    "outputId": "a5ea31d6-46bf-44ee-9ba7-5a5b162a946e"
   },
   "outputs": [],
   "source": [
    "def replace_layers(model, i, indexes, layers):\n",
    "    if i in indexes:\n",
    "        return layers[indexes.index(i)]\n",
    "    return model[i]\n",
    "\n",
    "def prune_vgg16_conv_layer(model, layer_index, filter_index):\n",
    "    _, conv = list(model.features._modules.items())[layer_index]\n",
    "    next_conv = None\n",
    "    offset = 1\n",
    "\n",
    "    while layer_index + offset <  len(model.features._modules.items()):\n",
    "        res =  list(model.features._modules.items())[layer_index+offset]\n",
    "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
    "            next_name, next_conv = res\n",
    "            break\n",
    "        offset = offset + 1\n",
    "          \n",
    "    new_conv = \\\n",
    "        torch.nn.Conv2d(in_channels = conv.in_channels, \\\n",
    "            out_channels = conv.out_channels - 1,\n",
    "            kernel_size = conv.kernel_size, \\\n",
    "            stride = conv.stride,\n",
    "            padding = conv.padding,\n",
    "            dilation = conv.dilation,\n",
    "            groups = conv.groups,\n",
    "            bias = True)\n",
    "\n",
    "    old_weights = conv.weight.data.cpu().numpy()\n",
    "    new_weights = new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "    new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n",
    "    new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :]\n",
    "    new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
    "\n",
    "    bias_numpy = conv.bias.data.cpu().numpy()\n",
    "\n",
    "    bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32)\n",
    "    bias[:filter_index] = bias_numpy[:filter_index]\n",
    "    bias[filter_index : ] = bias_numpy[filter_index + 1 :]\n",
    "    new_conv.bias.data = torch.from_numpy(bias).cuda()\n",
    "  \n",
    "    if not next_conv is None:\n",
    "        next_new_conv = \\\n",
    "            torch.nn.Conv2d(in_channels = next_conv.in_channels - 1,\\\n",
    "                out_channels =  next_conv.out_channels, \\\n",
    "                kernel_size = next_conv.kernel_size, \\\n",
    "                stride = next_conv.stride,\n",
    "                padding = next_conv.padding,\n",
    "                dilation = next_conv.dilation,\n",
    "                groups = next_conv.groups,\n",
    "                bias = True)\n",
    "\n",
    "        old_weights = next_conv.weight.data.cpu().numpy()\n",
    "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
    "\n",
    "        new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n",
    "        new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n",
    "        next_new_conv.weight.data = torch.from_numpy(new_weights).cuda()\n",
    "\n",
    "        next_new_conv.bias.data = next_conv.bias.data\n",
    "\n",
    "    if not next_conv is None:\n",
    "        features = torch.nn.Sequential(\n",
    "                *(replace_layers(model.features, i, [layer_index, layer_index+offset], \\\n",
    "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
    "        del model.features\n",
    "        del conv\n",
    "\n",
    "        model.features = features\n",
    "\n",
    "    else:\n",
    "        #Prunning the last conv layer. This affects the first linear layer of the classifier.\n",
    "        model.features = torch.nn.Sequential(\n",
    "                *(replace_layers(model.features, i, [layer_index], \\\n",
    "                    [new_conv]) for i, _ in enumerate(model.features)))\n",
    "        layer_index = 0\n",
    "        old_linear_layer = None\n",
    "        for _, module in model.classifier._modules.items():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                old_linear_layer = module\n",
    "                break\n",
    "            layer_index = layer_index  + 1\n",
    "\n",
    "        if old_linear_layer is None:\n",
    "            raise BaseException(\"No linear laye found in classifier\")\n",
    "        params_per_input_channel = old_linear_layer.in_features / conv.out_channels\n",
    "\n",
    "        new_linear_layer = \\\n",
    "            torch.nn.Linear(int(old_linear_layer.in_features) - int(params_per_input_channel), \n",
    "                old_linear_layer.out_features)\n",
    "\n",
    "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
    "        new_weights = new_linear_layer.weight.data.cpu().numpy()\t \t\n",
    "            \n",
    "        new_weights[:, :int(filter_index * params_per_input_channel)] = old_weights[:, :int(filter_index * params_per_input_channel)]\n",
    "        new_weights[:,int(filter_index * params_per_input_channel):] = old_weights[:,int((filter_index+1) * params_per_input_channel):]\n",
    "\n",
    "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
    "\n",
    "        new_linear_layer.weight.data = torch.from_numpy(new_weights).cuda()\n",
    "\n",
    "        classifier = torch.nn.Sequential(\n",
    "            *(replace_layers(model.classifier, i, [layer_index], \\\n",
    "                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
    "\n",
    "        del model.classifier\n",
    "        del next_conv\n",
    "        del conv\n",
    "        model.classifier = classifier\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning the original model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.torch/models/vgg16-397923af.pth\n",
      "553433881it [00:29, 18660839.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prunning took 25.68081307411194\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tmodel = models.vgg16(pretrained=True)\n",
    "\tmodel.train()\n",
    "\n",
    "\tt0 = time.time()\n",
    "\tmodel = prune_vgg16_conv_layer(model, 28, 10)\n",
    "\tprint(\"The prunning took\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9JgzFSjKXKE"
   },
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlLz0jOFsI2R"
   },
   "outputs": [],
   "source": [
    "class ModifiedVGG16Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedVGG16Model, self).__init__()\n",
    "\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        self.features = model.features\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class FilterPrunner:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # self.activations = []\n",
    "        # self.gradients = []\n",
    "        # self.grad_index = 0\n",
    "        # self.activation_to_layer = {}\n",
    "        self.filter_ranks = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        self.gradients = []\n",
    "        self.grad_index = 0\n",
    "        self.activation_to_layer = {}\n",
    "\n",
    "        activation_index = 0\n",
    "        for layer, (name, module) in enumerate(self.model.features._modules.items()):\n",
    "            x = module(x)\n",
    "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "                x.register_hook(self.compute_rank)\n",
    "                self.activations.append(x)\n",
    "                self.activation_to_layer[activation_index] = layer\n",
    "                activation_index += 1\n",
    "\n",
    "        return self.model.classifier(x.view(x.size(0), -1))\n",
    "\n",
    "    def compute_rank(self, grad):\n",
    "        activation_index = len(self.activations) - self.grad_index - 1\n",
    "        activation = self.activations[activation_index]\n",
    "        \n",
    "        number = (activation * grad)\n",
    "        \n",
    "        values = torch.sum(number, dim=0, keepdim = True).sum(dim=2, keepdim = True).sum(dim=3,keepdim = True)[0, :, 0, 0].data      \n",
    "          \n",
    "        # Normalize the rank by the filter dimensions\n",
    "        values = \\\n",
    "            values / (activation.size(0) * activation.size(2) * activation.size(3))\n",
    "\n",
    "        if activation_index not in self.filter_ranks:\n",
    "            self.filter_ranks[activation_index] = \\\n",
    "                torch.FloatTensor(activation.size(1)).zero_().cuda()\n",
    "\n",
    "        self.filter_ranks[activation_index] += values\n",
    "        self.grad_index += 1\n",
    "\n",
    "    def lowest_ranking_filters(self, num):\n",
    "        data = []\n",
    "        for i in sorted(self.filter_ranks.keys()):\n",
    "            for j in range(self.filter_ranks[i].size(0)):\n",
    "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
    "\n",
    "        return nsmallest(num, data, itemgetter(2))\n",
    "\n",
    "    def normalize_ranks_per_layer(self):\n",
    "        for i in self.filter_ranks:\n",
    "            v = torch.abs(self.filter_ranks[i])\n",
    "            v = v.cpu()\n",
    "            v = v / np.sqrt(torch.sum(v * v))\n",
    "            self.filter_ranks[i] = v.cpu()\n",
    "\n",
    "    def get_prunning_plan(self, num_filters_to_prune):\n",
    "        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n",
    "\n",
    "        # After each of the k filters are prunned,\n",
    "        # the filter index of the next filters change since the model is smaller.\n",
    "        filters_to_prune_per_layer = {}\n",
    "        for (l, f, _) in filters_to_prune:\n",
    "            if l not in filters_to_prune_per_layer:\n",
    "                filters_to_prune_per_layer[l] = []\n",
    "            filters_to_prune_per_layer[l].append(f)\n",
    "\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
    "            for i in range(len(filters_to_prune_per_layer[l])):\n",
    "                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
    "\n",
    "        filters_to_prune = []\n",
    "        for l in filters_to_prune_per_layer:\n",
    "            for i in filters_to_prune_per_layer[l]:\n",
    "                filters_to_prune.append((l, i))\n",
    "\n",
    "        return filters_to_prune\n",
    "\n",
    "class PrunningFineTuner_VGG16:\n",
    "    def __init__(self, train_path, test_path, model,num_filters_to_prune_per_iteration):\n",
    "        self.train_data_loader = loader(train_path)\n",
    "        self.test_data_loader = test_loader(test_path)\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.prunner = FilterPrunner(self.model) \n",
    "        self.model.train()\n",
    "        self.num_filters_to_prune_per_iteration = num_filters_to_prune_per_iteration\n",
    "        self.tracker = {'accuracy':[],'filters_pruned':[],'time':[]}\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (batch, label) in enumerate(self.test_data_loader):\n",
    "            batch = batch.cuda()\n",
    "            output = model(Variable(batch))\n",
    "            pred = output.data.max(1)[1]\n",
    "            correct += pred.cpu().eq(label).sum()\n",
    "            total += label.size(0)\n",
    "\n",
    "        print(\"accuracy :\", float(correct) / total)\n",
    "        self.tracker['accuracy'].append(float(correct) / total)\n",
    "        self.model.train()\n",
    "      \n",
    "    def train(self, optimizer = None, epochs = 20):\n",
    "        if optimizer is None:\n",
    "            optimizer = \\\n",
    "                optim.SGD(model.classifier.parameters(), \n",
    "                    lr=0.0001, momentum=0.9)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch: \", i)\n",
    "            self.train_epoch(optimizer)\n",
    "            self.test()\n",
    "        print(\"Finished fine tuning.\")\n",
    "\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.model.zero_grad()\n",
    "        input = Variable(batch)\n",
    "\n",
    "        if rank_filters:\n",
    "            output = self.prunner.forward(input)\n",
    "            self.criterion(output, Variable(label)).backward()\n",
    "        else:\n",
    "            self.criterion(self.model(input), Variable(label)).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        for batch, label in self.train_data_loader:\n",
    "            self.train_batch(optimizer, batch.cuda(), label.cuda(), rank_filters)\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.prunner.reset()\n",
    "\n",
    "        self.train_epoch(rank_filters = True)\n",
    "\n",
    "        self.prunner.normalize_ranks_per_layer()\n",
    "\n",
    "        return self.prunner.get_prunning_plan(num_filters_to_prune)\n",
    "\n",
    "    def total_num_filters(self):\n",
    "        filters = 0\n",
    "        for name, module in self.model.features._modules.items():\n",
    "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
    "                filters = filters + module.out_channels\n",
    "        return filters\n",
    "\n",
    "    def prune(self,num_filters_to_prune_per_iteration):\n",
    "        #Get the accuracy before prunning\n",
    "        self.test()\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        number_of_filters = self.total_num_filters()\n",
    "        iterations = int(float(number_of_filters) / self.num_filters_to_prune_per_iteration)\n",
    "\n",
    "        iterations = int(iterations * pruning_target)\n",
    "\n",
    "        print(\"Number of prunning iterations to reduce 75% filters: \", iterations)\n",
    "          \n",
    "        #Total time tracker    \n",
    "        self.tracker['time'].append(time.time())\n",
    "        for _ in range(iterations):\n",
    "            \n",
    "            #Iteration time tracker, ranking filters time tracker\n",
    "            self.tracker['time'].append(time.time())\n",
    "            print(\"Ranking filters.. \")\n",
    "\n",
    "            prune_targets = self.get_candidates_to_prune(self.num_filters_to_prune_per_iteration)\n",
    "            layers_prunned = {}\n",
    "            for layer_index, filter_index in prune_targets:\n",
    "                if layer_index not in layers_prunned:\n",
    "                    layers_prunned[layer_index] = 0\n",
    "                layers_prunned[layer_index] = layers_prunned[layer_index] + 1 \n",
    "            \n",
    "            #End ranking filters, start of pruning\n",
    "            self.tracker['time'].append(time.time())\n",
    "            \n",
    "            print(\"Layers that will be prunned\", layers_prunned)\n",
    "            self.tracker['filters_pruned'].append(layers_prunned)\n",
    "            \n",
    "            print(\"Prunning filters.. \")\n",
    "            model = self.model.cpu()\n",
    "            total = len(prune_targets)\n",
    "            for layer_index, filter_index in prune_targets:\n",
    "                model = prune_vgg16_conv_layer(model, layer_index, filter_index)\n",
    "            self.model = model.cuda()\n",
    "            \n",
    "            #End pruning filters, start finetuning\n",
    "            self.tracker['time'].append(time.time())\n",
    "            \n",
    "            message = str(100*float(self.total_num_filters()) / number_of_filters) + \"%\"\n",
    "            print(\"Filters prunned\", str(message))\n",
    "            self.test()\n",
    "            print(\"Fine tuning to recover from prunning iteration.\")\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "            self.train(optimizer, epochs = 5)\n",
    "            \n",
    "            #End of finetuning, end of iteration\n",
    "            self.tracker['time'].append(time.time())\n",
    "            \n",
    "        print(\"Finished. Going to fine tune the model a bit more\")\n",
    "        #End of total pruning, begin finetuning\n",
    "        self.tracker['time'].append(time.time())\n",
    "        self.train(optimizer, epochs = 10)\n",
    "        \n",
    "        #End of total pruning\n",
    "        self.tracker['time'].append(time.time())\n",
    "        torch.save(model.state_dict(), \"model_prunned {}\".format(num_filters_to_prune_per_iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the modified model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "97ECY2YMLCGr",
    "outputId": "5d3ee4b2-4c20-497b-ea9b-826fb8e52ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "accuracy : 0.926\n",
      "Epoch:  1\n",
      "accuracy : 0.952\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Epoch:  5\n",
      "accuracy : 0.978\n",
      "Epoch:  6\n",
      "accuracy : 0.978\n",
      "Epoch:  7\n",
      "accuracy : 0.98\n",
      "Epoch:  8\n",
      "accuracy : 0.976\n",
      "Epoch:  9\n",
      "accuracy : 0.982\n",
      "Finished fine tuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ModifiedVGG16Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedVGG16Model().cuda()\n",
    "fine_tuner = PrunningFineTuner_VGG16('../input/fcats_vs_dogs/train', '../input/fcats_vs_dogs/test', model,1056)\n",
    "fine_tuner.train(epochs = 10)\n",
    "torch.save(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdFq5Mp5LSYc"
   },
   "outputs": [],
   "source": [
    "def experiment(model,num_filters_to_prune_per_iteration):  \n",
    "    model = torch.load(\"model\").cuda()\n",
    "    fine_tuner = PrunningFineTuner_VGG16('../input/fcats_vs_dogs/train', '../input/fcats_vs_dogs/test', model,num_filters_to_prune_per_iteration)\n",
    "    fine_tuner.prune(num_filters_to_prune_per_iteration)\n",
    "    result = fine_tuner.tracker\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHDDc1z2nhIx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.97\n",
      "Number of prunning iterations to reduce 75% filters:  24\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {17: 8, 0: 3, 21: 13, 7: 1, 12: 4, 28: 51, 19: 9, 10: 4, 24: 20, 26: 16, 14: 1, 2: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 96.875%\n",
      "accuracy : 0.98\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.972\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.984\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 17, 28: 29, 24: 18, 26: 19, 17: 17, 14: 3, 21: 17, 5: 5, 10: 1, 7: 4, 12: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 93.75%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.966\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {24: 19, 28: 36, 17: 13, 5: 5, 26: 17, 19: 10, 14: 6, 21: 10, 7: 2, 0: 1, 10: 7, 12: 6}\n",
      "Prunning filters.. \n",
      "Filters prunned 90.625%\n",
      "accuracy : 0.968\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.976\n",
      "Epoch:  1\n",
      "accuracy : 0.978\n",
      "Epoch:  2\n",
      "accuracy : 0.982\n",
      "Epoch:  3\n",
      "accuracy : 0.978\n",
      "Epoch:  4\n",
      "accuracy : 0.958\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 13, 19: 20, 28: 33, 26: 22, 12: 3, 24: 16, 10: 3, 17: 15, 14: 4, 2: 1, 5: 1, 7: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 87.5%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.984\n",
      "Epoch:  1\n",
      "accuracy : 0.982\n",
      "Epoch:  2\n",
      "accuracy : 0.978\n",
      "Epoch:  3\n",
      "accuracy : 0.978\n",
      "Epoch:  4\n",
      "accuracy : 0.976\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 11, 12: 2, 28: 33, 24: 26, 26: 17, 7: 2, 17: 10, 10: 8, 21: 15, 2: 1, 14: 4, 0: 2, 5: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 84.375%\n",
      "accuracy : 0.974\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.98\n",
      "Epoch:  3\n",
      "accuracy : 0.97\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {26: 21, 19: 9, 28: 32, 24: 24, 21: 19, 14: 4, 17: 12, 0: 1, 12: 5, 7: 1, 10: 3, 5: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 81.25%\n",
      "accuracy : 0.974\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.964\n",
      "Epoch:  1\n",
      "accuracy : 0.968\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {24: 22, 28: 23, 17: 17, 26: 29, 14: 4, 19: 17, 21: 11, 12: 7, 10: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 78.125%\n",
      "accuracy : 0.98\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.98\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {26: 21, 21: 16, 19: 15, 17: 15, 28: 23, 24: 18, 5: 1, 7: 4, 14: 5, 12: 7, 10: 5, 0: 1, 2: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 75.0%\n",
      "accuracy : 0.976\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.974\n",
      "Epoch:  1\n",
      "accuracy : 0.986\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.978\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {28: 30, 17: 15, 10: 7, 24: 13, 12: 6, 21: 12, 26: 26, 19: 15, 5: 2, 14: 3, 0: 2, 2: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 71.875%\n",
      "accuracy : 0.972\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.976\n",
      "Epoch:  1\n",
      "accuracy : 0.974\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.978\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {28: 22, 26: 28, 21: 11, 17: 13, 0: 2, 19: 16, 7: 2, 24: 19, 5: 2, 12: 6, 14: 5, 2: 3, 10: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 68.75%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.982\n",
      "Epoch:  2\n",
      "accuracy : 0.978\n",
      "Epoch:  3\n",
      "accuracy : 0.972\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 23, 5: 3, 19: 13, 24: 14, 17: 11, 28: 23, 26: 22, 10: 7, 14: 5, 12: 7, 0: 2, 2: 1, 7: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 65.625%\n",
      "accuracy : 0.982\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.976\n",
      "Epoch:  1\n",
      "accuracy : 0.978\n",
      "Epoch:  2\n",
      "accuracy : 0.962\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 21, 19: 24, 28: 19, 24: 16, 10: 6, 17: 13, 7: 4, 12: 7, 2: 2, 14: 4, 26: 14, 5: 1, 0: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 62.5%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {10: 10, 21: 22, 24: 19, 12: 6, 17: 13, 19: 12, 28: 18, 26: 16, 7: 4, 14: 4, 0: 3, 5: 4, 2: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 59.375%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.976\n",
      "Epoch:  1\n",
      "accuracy : 0.984\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.966\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 18, 28: 8, 14: 5, 17: 22, 24: 23, 10: 5, 7: 6, 26: 17, 19: 12, 12: 12, 5: 2, 2: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 56.25%\n",
      "accuracy : 0.974\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.978\n",
      "Epoch:  4\n",
      "accuracy : 0.98\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {10: 9, 12: 9, 19: 19, 2: 2, 21: 15, 14: 9, 26: 21, 24: 18, 28: 11, 7: 1, 17: 15, 0: 1, 5: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 53.125%\n",
      "accuracy : 0.97\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.974\n",
      "Epoch:  1\n",
      "accuracy : 0.978\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.968\n",
      "Epoch:  4\n",
      "accuracy : 0.966\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 17, 26: 18, 10: 10, 19: 18, 12: 4, 24: 13, 17: 21, 28: 17, 14: 6, 7: 5, 5: 2, 2: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 50.0%\n",
      "accuracy : 0.966\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.982\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 24, 17: 22, 5: 3, 24: 18, 19: 20, 26: 14, 10: 8, 7: 5, 2: 1, 14: 4, 12: 7, 28: 5, 0: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 46.875%\n",
      "accuracy : 0.968\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.974\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.982\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 23, 28: 6, 12: 11, 10: 8, 24: 11, 17: 24, 21: 17, 14: 11, 5: 4, 26: 14, 7: 1, 0: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 43.75%\n",
      "accuracy : 0.986\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.98\n",
      "Epoch:  3\n",
      "accuracy : 0.972\n",
      "Epoch:  4\n",
      "accuracy : 0.966\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 18, 26: 22, 24: 17, 17: 17, 19: 18, 28: 15, 10: 9, 12: 4, 5: 1, 14: 11}\n",
      "Prunning filters.. \n",
      "Filters prunned 40.625%\n",
      "accuracy : 0.968\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.968\n",
      "Epoch:  2\n",
      "accuracy : 0.98\n",
      "Epoch:  3\n",
      "accuracy : 0.984\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {26: 17, 10: 10, 28: 6, 17: 16, 19: 17, 14: 9, 7: 5, 2: 2, 21: 22, 5: 5, 12: 7, 24: 15, 0: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 37.5%\n",
      "accuracy : 0.98\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.976\n",
      "Epoch:  1\n",
      "accuracy : 0.978\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.962\n",
      "Epoch:  4\n",
      "accuracy : 0.966\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 24, 24: 14, 14: 7, 17: 22, 26: 9, 12: 6, 10: 17, 21: 20, 5: 3, 2: 2, 7: 4, 28: 3, 0: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 34.375%\n",
      "accuracy : 0.968\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.98\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.968\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 26, 14: 8, 17: 15, 24: 19, 26: 22, 19: 18, 10: 6, 28: 5, 7: 3, 12: 7, 5: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 31.25%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.96\n",
      "Epoch:  4\n",
      "accuracy : 0.978\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 16, 17: 22, 10: 5, 14: 17, 7: 8, 24: 14, 21: 11, 28: 7, 12: 14, 5: 6, 0: 6, 26: 4, 2: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 28.125%\n",
      "accuracy : 0.972\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.972\n",
      "Epoch:  1\n",
      "accuracy : 0.978\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.972\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {17: 19, 28: 8, 19: 13, 14: 15, 10: 9, 21: 14, 12: 11, 0: 4, 26: 14, 24: 13, 2: 3, 5: 5, 7: 4}\n",
      "Prunning filters.. \n",
      "Filters prunned 25.0%\n",
      "accuracy : 0.972\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.974\n",
      "Epoch:  2\n",
      "accuracy : 0.978\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Finished. Going to fine tune the model a bit more\n",
      "Epoch:  0\n",
      "accuracy : 0.98\n",
      "Epoch:  1\n",
      "accuracy : 0.974\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.978\n",
      "Epoch:  5\n",
      "accuracy : 0.968\n",
      "Epoch:  6\n",
      "accuracy : 0.97\n",
      "Epoch:  7\n",
      "accuracy : 0.972\n",
      "Epoch:  8\n",
      "accuracy : 0.952\n",
      "Epoch:  9\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "accuracy : 0.966\n",
      "Number of prunning iterations to reduce 75% filters:  12\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 28, 26: 43, 12: 4, 17: 18, 21: 26, 28: 88, 24: 44, 0: 1, 14: 2, 10: 5, 7: 1, 2: 1, 5: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 93.75%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.974\n",
      "Epoch:  1\n",
      "accuracy : 0.964\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.97\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 27, 28: 88, 26: 47, 21: 35, 24: 26, 12: 6, 10: 9, 17: 17, 14: 2, 7: 2, 5: 5}\n",
      "Prunning filters.. \n",
      "Filters prunned 87.5%\n",
      "accuracy : 0.966\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.968\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.976\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {24: 52, 26: 38, 28: 56, 19: 28, 17: 28, 21: 37, 14: 6, 0: 1, 10: 10, 12: 7, 7: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 81.25%\n",
      "accuracy : 0.972\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.97\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {26: 41, 28: 66, 24: 44, 14: 8, 19: 27, 21: 31, 12: 10, 10: 6, 5: 3, 17: 24, 2: 2, 7: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 75.0%\n",
      "accuracy : 0.976\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.974\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.97\n",
      "Epoch:  4\n",
      "accuracy : 0.978\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {28: 48, 24: 28, 21: 33, 19: 33, 26: 43, 17: 35, 12: 14, 10: 8, 5: 2, 14: 13, 0: 3, 2: 3, 7: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 68.75%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.964\n",
      "Epoch:  3\n",
      "accuracy : 0.972\n",
      "Epoch:  4\n",
      "accuracy : 0.97\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {24: 44, 10: 17, 21: 40, 28: 20, 14: 13, 17: 39, 19: 33, 26: 41, 0: 3, 5: 1, 12: 9, 7: 3, 2: 1}\n",
      "Prunning filters.. \n",
      "Filters prunned 62.5%\n",
      "accuracy : 0.98\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.972\n",
      "Epoch:  1\n",
      "accuracy : 0.984\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.982\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {12: 13, 24: 36, 7: 5, 17: 31, 14: 6, 21: 25, 26: 47, 19: 37, 28: 47, 2: 3, 10: 8, 0: 1, 5: 5}\n",
      "Prunning filters.. \n",
      "Filters prunned 56.25%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.974\n",
      "Epoch:  1\n",
      "accuracy : 0.982\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.972\n",
      "Epoch:  4\n",
      "accuracy : 0.976\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {17: 24, 19: 54, 26: 44, 24: 39, 14: 9, 21: 44, 5: 5, 10: 12, 28: 13, 12: 14, 0: 1, 7: 3, 2: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 50.0%\n",
      "accuracy : 0.972\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.984\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 34, 26: 42, 24: 47, 2: 4, 10: 14, 19: 30, 5: 4, 12: 12, 14: 18, 17: 35, 28: 12, 7: 7, 0: 5}\n",
      "Prunning filters.. \n",
      "Filters prunned 43.75%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.966\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.978\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {0: 5, 24: 23, 17: 40, 19: 36, 10: 20, 26: 35, 21: 35, 14: 20, 5: 7, 12: 19, 7: 9, 28: 12, 2: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 37.5%\n",
      "accuracy : 0.966\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.962\n",
      "Epoch:  4\n",
      "accuracy : 0.966\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 29, 24: 32, 19: 46, 14: 22, 2: 7, 26: 11, 12: 24, 5: 11, 28: 4, 17: 43, 10: 18, 7: 8, 0: 9}\n",
      "Prunning filters.. \n",
      "Filters prunned 31.25%\n",
      "accuracy : 0.964\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.982\n",
      "Epoch:  1\n",
      "accuracy : 0.964\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {21: 41, 26: 17, 7: 10, 10: 21, 17: 56, 2: 2, 5: 10, 12: 19, 14: 18, 19: 31, 24: 27, 28: 10, 0: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 25.0%\n",
      "accuracy : 0.968\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.972\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.97\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Finished. Going to fine tune the model a bit more\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.982\n",
      "Epoch:  4\n",
      "accuracy : 0.97\n",
      "Epoch:  5\n",
      "accuracy : 0.98\n",
      "Epoch:  6\n",
      "accuracy : 0.98\n",
      "Epoch:  7\n",
      "accuracy : 0.968\n",
      "Epoch:  8\n",
      "accuracy : 0.978\n",
      "Epoch:  9\n",
      "accuracy : 0.98\n",
      "Finished fine tuning.\n",
      "accuracy : 0.964\n",
      "Number of prunning iterations to reduce 75% filters:  6\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 46, 17: 43, 28: 172, 24: 79, 26: 92, 21: 42, 5: 8, 0: 2, 7: 4, 14: 12, 12: 11, 10: 14, 2: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 87.5%\n",
      "accuracy : 0.97\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.98\n",
      "Epoch:  1\n",
      "accuracy : 0.968\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.966\n",
      "Epoch:  4\n",
      "accuracy : 0.96\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {28: 99, 5: 10, 24: 71, 21: 64, 19: 54, 26: 87, 17: 70, 10: 22, 0: 1, 12: 25, 14: 17, 7: 6, 2: 2}\n",
      "Prunning filters.. \n",
      "Filters prunned 75.0%\n",
      "accuracy : 0.96\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.978\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.976\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {17: 57, 28: 85, 21: 82, 26: 84, 24: 68, 19: 64, 7: 9, 0: 10, 12: 16, 14: 21, 10: 18, 5: 9, 2: 5}\n",
      "Prunning filters.. \n",
      "Filters prunned 62.5%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.99\n",
      "Epoch:  1\n",
      "accuracy : 0.978\n",
      "Epoch:  2\n",
      "accuracy : 0.976\n",
      "Epoch:  3\n",
      "accuracy : 0.976\n",
      "Epoch:  4\n",
      "accuracy : 0.976\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {26: 82, 21: 88, 28: 57, 19: 70, 14: 26, 24: 77, 17: 64, 10: 27, 7: 9, 2: 5, 0: 4, 12: 16, 5: 3}\n",
      "Prunning filters.. \n",
      "Filters prunned 50.0%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.972\n",
      "Epoch:  4\n",
      "accuracy : 0.974\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {26: 66, 0: 6, 10: 29, 19: 75, 17: 74, 24: 88, 28: 27, 12: 29, 5: 6, 14: 31, 21: 76, 2: 8, 7: 13}\n",
      "Prunning filters.. \n",
      "Filters prunned 37.5%\n",
      "accuracy : 0.97\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.972\n",
      "Epoch:  1\n",
      "accuracy : 0.98\n",
      "Epoch:  2\n",
      "accuracy : 0.97\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {19: 87, 12: 42, 10: 35, 17: 97, 21: 65, 28: 29, 14: 49, 2: 11, 26: 33, 7: 15, 24: 36, 5: 18, 0: 11}\n",
      "Prunning filters.. \n",
      "Filters prunned 25.0%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.986\n",
      "Epoch:  1\n",
      "accuracy : 0.976\n",
      "Epoch:  2\n",
      "accuracy : 0.972\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.966\n",
      "Finished fine tuning.\n",
      "Finished. Going to fine tune the model a bit more\n",
      "Epoch:  0\n",
      "accuracy : 0.97\n",
      "Epoch:  1\n",
      "accuracy : 0.968\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.976\n",
      "Epoch:  5\n",
      "accuracy : 0.974\n",
      "Epoch:  6\n",
      "accuracy : 0.974\n",
      "Epoch:  7\n",
      "accuracy : 0.976\n",
      "Epoch:  8\n",
      "accuracy : 0.978\n",
      "Epoch:  9\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "accuracy : 0.97\n",
      "Number of prunning iterations to reduce 75% filters:  3\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {10: 31, 28: 316, 24: 165, 26: 170, 19: 101, 17: 98, 21: 97, 12: 20, 7: 14, 14: 26, 5: 9, 0: 5, 2: 4}\n",
      "Prunning filters.. \n",
      "Filters prunned 75.0%\n",
      "accuracy : 0.984\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.978\n",
      "Epoch:  1\n",
      "accuracy : 0.968\n",
      "Epoch:  2\n",
      "accuracy : 0.982\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.972\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {17: 144, 19: 148, 21: 169, 26: 158, 28: 109, 24: 137, 12: 46, 10: 34, 7: 23, 14: 48, 2: 9, 0: 14, 5: 17}\n",
      "Prunning filters.. \n",
      "Filters prunned 50.0%\n",
      "accuracy : 0.978\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.964\n",
      "Epoch:  1\n",
      "accuracy : 0.972\n",
      "Epoch:  2\n",
      "accuracy : 0.974\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.968\n",
      "Finished fine tuning.\n",
      "Ranking filters.. \n",
      "Layers that will be prunned {14: 90, 17: 151, 26: 111, 24: 120, 7: 29, 21: 151, 10: 75, 19: 157, 12: 80, 2: 10, 28: 46, 5: 30, 0: 6}\n",
      "Prunning filters.. \n",
      "Filters prunned 25.0%\n",
      "accuracy : 0.972\n",
      "Fine tuning to recover from prunning iteration.\n",
      "Epoch:  0\n",
      "accuracy : 0.964\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.966\n",
      "Epoch:  3\n",
      "accuracy : 0.974\n",
      "Epoch:  4\n",
      "accuracy : 0.98\n",
      "Finished fine tuning.\n",
      "Finished. Going to fine tune the model a bit more\n",
      "Epoch:  0\n",
      "accuracy : 0.966\n",
      "Epoch:  1\n",
      "accuracy : 0.97\n",
      "Epoch:  2\n",
      "accuracy : 0.98\n",
      "Epoch:  3\n",
      "accuracy : 0.98\n",
      "Epoch:  4\n",
      "accuracy : 0.97\n",
      "Epoch:  5\n",
      "accuracy : 0.966\n",
      "Epoch:  6\n",
      "accuracy : 0.98\n",
      "Epoch:  7\n",
      "accuracy : 0.972\n",
      "Epoch:  8\n",
      "accuracy : 0.976\n",
      "Epoch:  9\n",
      "accuracy : 0.966\n",
      "Finished fine tuning.\n"
     ]
    }
   ],
   "source": [
    "experiments = [132,264,528,1056]\n",
    "result = {}\n",
    "for num_filters_to_prune_per_iteration in experiments: \n",
    "    result[num_filters_to_prune_per_iteration] = experiment(model,num_filters_to_prune_per_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(result, open(\"result.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch Pruning (1).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
